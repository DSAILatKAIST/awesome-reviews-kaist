---
description : Fan Lu / Modeling User Behavior with Graph Convolution for Personalized Product Search / WWW-2022
---

# **SBG(Successive Behavior Graph)**

# 1. Problem Definition

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Latent space ê¸°ë°˜ ê°œì¸í™” ìƒí’ˆê²€ìƒ‰ì„ êµ¬í˜„í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ìœ ì € íŠ¹ì„± ëª¨ë¸ë§ì´ ê°€ì§€ëŠ” í•œê³„ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ ìœ ì €ì˜ ì§§ì€ í–‰ë™ì„ í•˜ë‚˜ì˜ ì„¸ì…˜ìœ¼ë¡œ êµ¬ì„±í•˜ëŠ”, Successive Behavior Graph(ì´í•˜ SBG)ë¥¼ ì œì•ˆí•œë‹¤.

ë˜í•œ ì´ë ‡ê²Œ êµ¬ì„±í•œ ê·¸ë˜í”„ì— GCNì„ í†µí•´ ì–»ì€ Graph-enriched embedding ì„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ì´ë¯¸ ì˜ ì•Œë ¤ì§„ ZAM([A Zero Attention Model for Personalized Product Search](https://arxiv.org/pdf/1908.11322.pdf) / CIKM-2019) ì— ì ìš©ì‹œí‚´ìœ¼ë¡œì„œ ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ê°€ì§„ ì‚¬ìš©ì íŠ¹ì„± ëª¨ë¸ë§ì„ êµ¬í˜„í•˜ì˜€ë‹¤.

# 2. Motivation

ì´ì»¤ë¨¸ìŠ¤ì˜ ë°œì „ì— ë”°ë¼ ìƒí’ˆ ê²€ìƒ‰ëª¨ë“ˆì˜ ì¤‘ìš”ì„±ì´ ì»¤ì§€ê³  ìˆë‹¤. ì´ë•Œ ìƒí’ˆ ê²€ìƒ‰(Product search)ì€ ê¸°ì¡´ì˜ ì›¹ ê²€ìƒ‰(Web search)ê³¼ ëª…í™•íˆ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‹¤

- ì›¹í˜ì´ì§€ì™€ ë‹¬ë¦¬ ì œëª©, ë¦¬ë·°ì™€ ê°™ì€ ì§§ì€ í…ìŠ¤íŠ¸ ì •ë³´ë§Œì„ ì´ìš©í•˜ëŠ” ì 
- Ontology, Spec sheet, Figures ì™€ ê°™ì€ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë“¤ì„ í¬í•¨í•œë‹¤ëŠ” ì 
- ì›¹ê³¼ ë‹¬ë¦¬ ì‚¬ìš©ìì™€ ë¬¼í’ˆê°„ì— ê²€ìƒ‰, í´ë¦­, ë¦¬ë·°, êµ¬ë§¤ ì™€ ê°™ì´ ë‹¤ì–‘í•œ relationì´ ì¡´ì¬í•˜ëŠ”ì (í’ë¶€í•œ ì •ë³´)

### Limitation

ì´ëŸ¬í•œ í’ë¶€í•œ ì •ë³´ë“¤ì„ ë‹¤ë£¨ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì œì•ˆë˜ì—ˆìœ¼ë©° ì¤‘ ì´ ì¤‘ ì‚¬ìš©ìì™€ ì•„ì´í…œ, ì¿¼ë¦¬ë¥¼ ê°™ì€ ê³µê°„ìƒì— ì˜¬ë ¤ë†“ëŠ” Latent space based modelë“¤ì´ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ ì´ì „ ë°©ë²•ë¡ ë“¤ì´ í•´ê²°í•˜ì§€ ëª»í•œ ëª‡ê°€ì§€ ë…¼ì˜ì ì´ ìˆëŠ”ë°, ì´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

1. ìœ ì €ì˜ life time behaviorë¥¼ í•˜ë‚˜ì˜ preferenceë¡œ ë‹´ê¸°ì—ëŠ” ìœ ì €ì˜ ê´€ì‹¬ì‚¬ ë³€í™”ë‚˜, ë¹„ì˜ë„ì  í–‰ë™ë“¤ì— ì˜í•œ ë…¸ì´ì¦ˆë¡œ ëª…í™•í•œ ëª¨ë¸ë§ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤.
2. ìœ„ ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ìœ ì €ì˜ ìµœê·¼ í–‰ë™ë§Œì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ì€ë° ì´ëŠ” ë§ì€ ì •ë³´ë¥¼ ë‚­ë¹„í•˜ê²Œ ë˜ê³ , ì¶©ë¶„í•œ íŠ¹ì„±ì„ ëª¨ë¸ë§ í•  ìˆ˜ ì—†ë‹¤.

### Propose

ê¸°ì¡´ ë°©ë²•ë¡ ì´ ê°€ì§€ëŠ” í•œê³„ì ë“¤ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ì œì•ˆí•œë‹¤.

- SBGë¥¼ í†µí•œ ìƒí’ˆê°„ ì—°ê´€ê´€ê³„ í™•ì¥
  - ë‹¨ê¸°ì ì¸ ì—°ì†í–‰ë™ë“¤ì„ í•˜ë‚˜ì˜ ì„¸ì…˜ìœ¼ë¡œ ì‚¼ì•„, ê¸€ë¡œë²Œ í–‰ë™ê·¸ë˜í”„ ìƒì„±.
  - ê°œê°œì¸ì˜ í–‰ë™ì´ ì•„ë‹Œ, ìœ ì € ì „ì²´ì˜ ê¸€ë¡œë²Œ í–‰ë™ ê·¸ë˜í”„ë¥¼ í†µí•´ ì ì¬ëœ ì•„ì´í…œ ê°„ ì—°ê´€ ê´€ê³„ë¥¼ ìœ ì € í–‰ë™ì„ ë§¤ê°œë¡œ ì—°ê²°ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±
- GCNì„ í†µí•œ ì•„ì´í…œ ëª¨ë¸ë§ ê°•í™”
  - Graph convolution(GCN)ì„ í†µí•´ ì—°ê´€ëœ ì•„ì´í…œë“¤ì„ ì ì¬ ê³µê°„ìƒì— ë” ë¹„ìŠ·í•˜ê²Œ ìœ„ì¹˜ì‹œí‚´ìœ¼ë¡œì„œ í’ë¶€í•œ ìƒí’ˆ í‘œí˜„ ì„ë² ë”©ì„ ë§Œë“¦
  - **GCN II** ì—ì„œ ì˜ê°ì„ ë°›ì•„, Jumping connection ì„ ê°€ì§€ëŠ” efficient graph convolutionë¥¼ ì‚¬ìš©

### Contributions

1. ìƒí’ˆ ê²€ìƒ‰ì— grah convolutionì„ ì ìš©ì‹œí‚¨ ì²«ë²ˆì§¸ ì‚¬ë¡€ì´ë‹¤.
2. SBG ë¥¼ í†µí•´ ì§€ì—½ì ì¸ ê´€ê³„ ë¿ë§Œ ì•„ë‹ˆë¼ global behavior patternë„ ë°œê²¬ ê°€ëŠ¥í•˜ë‹¤.
3. 8ê°œì˜ amazon benchmarkë¥¼ í†µí•œ ê²€ì¦í•˜ì˜€ë‹¤.

# 3. Method

## 3.0 Background - Latent space ê¸°ë°˜ ëª¨ë¸

ğŸ’¡**ê²€ìƒ‰ì˜ ëª©ì  : Userê°€ Queryë¥¼ ì…ë ¥í• ë•Œ êµ¬ë§¤í•  í™•ë¥ ì´ ê°€ì¥ ë†’ì€ Itemì„ ë³´ì—¬ì£¼ëŠ”ê²ƒ**

$$q$$ : ìœ ì €ê°€ ì…ë ¥í•œ query

$$u$$ : ìœ ì €

$$i$$ : ì•„ì´í…œ(ìƒí’ˆ)

$$
P(i \mid u, q)=\frac{\exp \left(\boldsymbol{i} \cdot \boldsymbol{M}_{\boldsymbol{u q}}\right)}{\sum_{i^{\prime} \in I_{q}} \exp \left(\boldsymbol{i}^{\prime} \cdot \boldsymbol{M}_{\boldsymbol{u q}}\right)}
$$

> $$i \in \mathbb{R}^{\alpha}$$ is the embedding representation of item , $M_{uq}$ is a joint model of user-query pair (u,q)
> **Probability** of whether $i$ would be purchased by $u$ given $q$

---

### 3.0.1 QEM(Query Embedding Model)

ğŸ’¡**non-personalized product search**

**ê°œì¸í™” ê¹Œì§€ëŠ” ì•„ë‹ˆê³ , query ì™€ item embedding ì„ ë§ì¶”ì.**

### `Query`

$$
M_{uq} = q
$$

(User embedding ì´ ì—†ìŒì„ ë³¼ ìˆ˜ ìˆë‹¤)

> $q \in \mathbb{R}^{\alpha}$ is the embedding representation of the query q.

queryëŠ” ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ ì…ë ¥ë˜ê¸° ë•Œë¬¸ì—, request time ë‚´ì— ê³„ì‚°ë˜ì–´ì•¼ í•¨

qì˜ ê³„ì‚°ì€ ë‹¤ìŒê³¼ ê°™ì´ ì´ë¤„ì§„ë‹¤.

$$
\boldsymbol{q}=\phi\left(\left\{w_{q} \mid w_{q} \in q\right\}\right)=\tanh \left(\boldsymbol{W}_{\phi} \cdot \frac{\sum_{w_{q} \in q} \boldsymbol{w}_{\boldsymbol{q}}}{|q|}+\boldsymbol{b}_{\phi}\right)
$$

> where $w_{q} \in \mathbb{R}^{\alpha}$ is the embedding of a word $w_{q}$ in $q,|q|$ is the length of the query, and $\boldsymbol{W}{\phi} \in \mathbb{R}^{\alpha \times \alpha}$ _and_ $\boldsymbol{b}{\phi} \in \mathbb{R}^{\alpha}$ are two parameters learned in the training process.

### `Item`

Item embedding ì€ Paragraph vector(doc2vec)ì—ì„œ insightë¥¼ ì–»ì–´ì„œ ì‚¬ìš©í–ˆë‹¤.

![doc2vecì´ information retrival taskì—ì„œ ì ì€ errorë¥¼ ë³´ì˜€ê¸° ë•Œë¬¸](<".gitbook/2022-spring-assets/KimDaehee_1/SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled.png">)

doc2vecì´ information retrival taskì—ì„œ ì ì€ errorë¥¼ ë³´ì˜€ê¸° ë•Œë¬¸

$$
P\left(T_{i} \mid i\right)=\prod_{\boldsymbol{w} \in T_{i}} \frac{\exp (\boldsymbol{w} \cdot \boldsymbol{i})}{\sum_{w^{\prime} \in V} \exp \left(\boldsymbol{w}^{\prime} \cdot \boldsymbol{i}\right)}
$$

> $T_i$ be a set of words associated with an item $i$ (ië²ˆì§¸ item ì— ëŒ€í•œ ë‹¨ì–´ë“¤)
> $w \in \mathbb{R}^{\alpha}$ is the embedding of a word and $V$ is the vocabulary of all possible words.

---

### 3.0.2 HEM(Hierarchical embedding model)

[Learning a hierarchical embedding model for personalized product search(SIGIR-2017)](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3077136.3080813&hl=ko&sa=T&oi=gsb-gga&ct=res&cd=0&d=15736059002742053164&ei=pstjYtiTHYySyASZk6HgCA&scisig=AAGBfm17kfq7KLvb8_VrBirjKb8qxDT-7w)

<aside>
ğŸ’¡ **QEM+User embedding**
ê°œì¸í™”ëœ ì¶”ì²œì„ ìœ„í•´ User embedding ì„ ì‚¬ìš©í•˜ì.

</aside>

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%201.png>)

$$
M_{uq} = q+u
$$

**user ì™€ queryëŠ” ë…ë¦½ì´ë¼ëŠ” ê°€ì •í•˜ì— ëª¨ë¸ë§**

### `User`

$$
P\left(T_{u} \mid u\right)=\prod_{\boldsymbol{w} \in T_{u}} \frac{\exp (\boldsymbol{w} \cdot \boldsymbol{u})}{\sum_{w^{\prime} \in V} \exp \left(\boldsymbol{w}^{\prime} \cdot \boldsymbol{u}\right)}
$$

> $T_u$ could be any text written or associated to u, such as product reviews or the descriptions of items that the user has purchased.

itemê³¼ ê°™ì´ userâ€™s associated text ë¥¼ ì´ìš©í•´ embeddingì„ ì–»ì–´ì„œ $M_{uq}$ì— ë°˜ì˜í•¨.

---

### 3.0.3.AEM(Attention Embedding model)

<aside>
ğŸ’¡ **User preferences are not independent of query intents**
ì–´íƒ ì…˜ì„ í†µí•´ ì‚¬ìš©ìì˜ êµ¬ë§¤ í–‰ë™ì„ ì¶”ê°€í•´ë³´ì!

</aside>

$I_u$ ê°€ user $u$ ê°€ êµ¬ë§¤í•œ item set ì¼ë•Œ, user embedding uëŠ”:

$$
\boldsymbol{u}=\sum_{i \in I_{u}} \frac{\exp (f(q, i))}{\sum_{i^{\prime} \in I_{u}} \exp \left(f\left(q, i^{\prime}\right)\right)} \boldsymbol{i}
$$

$f (q,i)$ëŠ” $I_u$ì˜ ê° item i ë“¤ì´ í˜„ì¬ query $q$ ì— ëŒ€í•œ attention function

$$
f(q, i)=\left(i \cdot \tanh \left(\boldsymbol{W}_{f} \cdot q+b_{f}\right)\right) \cdot \boldsymbol{W}_{h}
$$

$\boldsymbol{W}_{h} \in \mathbb{R}^{\beta}, \boldsymbol{W}_{f} \in \mathbb{R}^{\alpha \times \beta \times \alpha}, \boldsymbol{b}_{f} \in \mathbb{R}^{\alpha \times \beta}$, and $\beta$ is a hyperparameter that controls the number of hidden units in the attention network.

$$
M_{uq} = q+u
$$

---

### 3.0.4 ZAM(Zero Attention Model)

[A Zero Attention Model for Personalized Product Search(CIKM â€™19)](https://arxiv.org/pdf/1908.11322.pdf)

<aside>
ğŸ’¡ **Advanced AEM**
Zero ****attention strategyë¥¼ í†µí•´ ì„±ëŠ¥ ê°œì„ 

</aside>

Userê°€ í•´ë‹¹ queryì— ê´€ë ¨ëœ êµ¬ë§¤ê¸°ë¡ì´ ì „í˜€ ì—†ëŠ” ê²½ìš°ë‚˜(cold start), ì„±í–¥ê³¼ ë¬´ê´€í•˜ê²Œ ì¿¼ë¦¬ì— ë”°ë¥¸ ê²°ê³¼ê°€ ì •í•´ì ¸ ìˆëŠ” ê²½ìš°(dominant brand)ì˜ ì„±ëŠ¥ í•˜ë½ì„ ê°œì„ í•˜ê³ ì Zero attentntion strategy ì ìš©

> The main **difference** between ZAM and AEM is that, instead of attending to the userâ€™s previous purchases only, ZAM **allows the attention network to attend to a Zero Vector.**

$$
\boldsymbol{u}=\sum_{i \in I_{u}} \frac{\exp (f(q, i))}{\exp (f(q, \mathbf{0}))+\sum_{i^{\prime} \in I_{u}} \exp \left(f\left(q, i^{\prime}\right)\right)} \boldsymbol{i}
$$

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%202.png>)

## 3.1. Search Framework

### 3.1.1 **Product retrieval task**

<aside>
ğŸ’¡ **ê²€ìƒ‰ì˜ ëª©ì  : Userê°€ Queryë¥¼ ì…ë ¥í• ë•Œ êµ¬ë§¤í•  í™•ë¥ ì´ ê°€ì¥ ë†’ì€ Itemì„ ë³´ì—¬ì£¼ëŠ”ê²ƒ**

Rank Item by probability \*\*\*\*of whether $i$ would be purchased by $u$ given $q$ì•„

</aside>

ê¸°ë³¸ì ìœ¼ë¡œ Latent space based ëª¨ë¸ë§ì„ ì°¨ìš©

$$
P(i \mid u, q)=\frac{\exp \left(f\left(\boldsymbol{i}, \boldsymbol{M}_{u q}\right)\right)}{\sum_{i^{\prime} \in C} \exp \left(f\left(\boldsymbol{i}^{\prime}, \boldsymbol{M}_{u q}\right)\right)}
$$

> $i \in \mathbb{R}^{\alpha}$ is the embedding representation of item
>
> $M_{uq}$ is a joint model of user-query pair (u,q)
>
> $f$ is similarity measure function. (ë…¼ë¬¸ì—ì„  cosine similarity)

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%203.png>)

### 3.1.2 **Language Modeling Task**

$i, u, q$ ì¤‘ ì´ë²ˆ ë…¼ë¬¸ì˜ í•µì‹¬ì´ ë˜ëŠ” SBG, GCNì„ ì´ìš©í•˜ëŠ”ê²ƒì€ $u$ embedding
$i,q$ëŠ” ì´ì „ê³¼ í¬ê²Œ ë‹¤ë¥´ì§€ ì•ŠìŒ

$$
P\left(T_{i} \mid i\right)=\prod_{w \in T_{i}} \frac{\exp (\tau(w, i))}{\sum_{w^{\prime} \in V} \exp \left(\tau\left(w^{\prime}, i\right)\right)}
$$

maximize likelihood í•˜ëŠ” ê³¼ì •ì—ì„œ ìƒê¸°ëŠ” item embedding

$$
\boldsymbol{q}=\phi\left(\left\{w_{q} \mid w_{q} \in q\right\}\right)=\tanh \left(\boldsymbol{W}_{\phi} \cdot \frac{\sum_{w_{q} \in q} \boldsymbol{w}_{\boldsymbol{q}}}{|q|}+\boldsymbol{b}_{\phi}\right)
$$

$\phi$ëŠ” ì—¬íƒ€ non-linear sequential encoder(LSTM,Transformer ë“±)ì´ ë  ìˆ˜ ìˆì§€ë§Œ, ë³´í†µ queryëŠ” ì§§ê³ , ë‹¨ì–´ ìˆœì„œë˜í•œ ê·¸ë¦¬ ì¤‘ìš”ì¹˜ ì•Šì•„ ì €ìëŠ” ê¸°ì¡´ì˜ averageì™€ ê°™ì€ê²ƒì„ ì‚¬ìš©

## 3.2 Efficient Graph Convolution with Jumping Conection

### 3.2.1 **Efficient Graph Convolution**

- Vanila GCN

  ê°€ì¥ ê¸°ë³¸ì ì¸ GCNêµ¬ì¡°

  $$
  \boldsymbol{H}^{(l)}=\sigma\left({A} \boldsymbol{H}^{(l-1)} W^{(l)}\right)
  $$

- Common GCN(self loop, normalized)
  í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” GCN êµ¬ì¡°, ì¼ë°˜ì ìœ¼ë¡œ GCN êµ¬ì¡°ë¥¼ ë§í•œë‹¤ë©´ ì´ê²ƒì„ ì˜ë¯¸í•œë‹¤.

      $$
      \boldsymbol{H}^{(l)}=\sigma\left(\hat{A} \boldsymbol{H}^{(l-1)} W^{(l)}\right)
      $$

      $\hat{A}=I+D^{-1} A$ is the ([normalized](https://woosikyang.github.io/Graph-Convolutional-Network.html)) adjacency matrix with self-loops,

      $D$ is the degree matrix.

      $H^{(l)}$ is the node embeddings produced by layer $l$.

      $W^{(l)}$ denotes trainable parameters

      $\sigma$ is a non-linear function such as $\operatorname{ReLU}(\cdot)$

- Efficient Graph Concovoluition ~~Network~~
  ì €ìë“¤ì˜ ê²½í—˜ì  ì—°êµ¬ì— ë”°ë¼ ì¼ë°˜ì ì¸ GCNì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ ë³´ë‹¤ efficient graph convolutionì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤ê³  ì–¸ê¸‰í•¨.
  > _However, as observed from our empirical study, the projection layers may **distort the semantic product representations** learned by **language modeling** in methods such as ZAM or HEM._
  $$
  \boldsymbol{H}^{(l)}=\left(\omega \boldsymbol{I}+(1-\omega) \boldsymbol{D}^{-1} \boldsymbol{A}\right) \boldsymbol{H}^{(l-1)}
  $$
  $\omega$ ëŠ” ìê¸° ìì‹ ì˜ ë…¸ë“œë¥¼ ì „íŒŒí•˜ëŠ” ì •ë³´ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°

### 3.2.2 **Jumping Graph Convolution Layer**

GNN êµ¬ì¡°ì—ì„œ ê³ ì°¨ì›ì˜ ì •ë³´(High order information)ì„ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë§ì€ ì¸µì„ ìŒ“ì•„ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµ ì‹œì¼œì•¼ í•œë‹¤. ë‹¨ ê·¸ë˜í”„ë¥¼ ë†’ì´ ìŒ“ì„ ìˆ˜ë¡ ì„ë² ë”©ì´ í•œ ì§€ì ìœ¼ë¡œ ëª¨ì´ëŠ” Over smoothing problem ì´ ì¼ì–´ë‚œë‹¤.

[Simple and Deep Graph Convolutional Networks](https://scholar.google.co.kr/scholar_url?url=http://proceedings.mlr.press/v119/chen20v/chen20v.pdf&hl=ko&sa=X&ei=hjEyYvn_AYjwyAS2o4mYAw&scisig=AAGBfm2_hCGohcaQRDILYCo-3dLq2_o3hQ&oi=scholarr)ì—ì„œ ì œì•ˆí•œ **GCN II**ì˜ idea ì— ë”°ë¼residual termì„ ì¶”ê°€í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ $H^0$ë¥¼ feeding í•´ì¤€ë‹¤.

$$
\tilde{\boldsymbol{H}}^{(l)}=\left(\omega \boldsymbol{I}+(1-\omega) \boldsymbol{D}^{-1} \boldsymbol{A}\right)\left(\beta \boldsymbol{H}^{(0)}+(1-\beta) \tilde{\boldsymbol{H}}^{(l-1)}\right)
$$

ğ›½ ëŠ” $H^{0}$ì˜ feedingì„ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°

## 3.3 Modeling User Behavior with Graph Convolution(SBG)

### 3.3.1 **Graph Construction**

Successive behavior graphë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•´, successiveê°€ ë­”ì§€ ì •ì˜í•´ì•¼ í•œë‹¤.

í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” íŠ¹ì •í•œ ê¸¸ì´ Rì„ í•œ ì„¸ì…˜ìœ¼ë¡œ ì„¤ì •í–ˆìŒ

> \*If the time interval between **two consecutive actions is within a period ğ‘…** (e.g., a day, a week, or a month), the **two actions are considered as successive** and will be placed in the **same successive behavior sequence\***

$ğº_{ğ‘†ğµ}$ ëŠ” ì´ë ‡ê²Œ êµ¬ì„±ëœ ì‹œí€€ìŠ¤ì™€ ìƒí’ˆê°„ì˜ ì´ë¶„ê·¸ë˜í”„
$G_{SB}$ì˜ edge ëŠ” ìƒí’ˆ i ê°€ ì‹œí€€ìŠ¤ S ì— ìˆì„ ì‹œ $ğº_{ğ‘†ğµ}(ğ‘–, ğ‘†) = 1$ë¡œ í‘œí˜„

### 3.3.2 **Enriching Product Representations with Graph Convolution**

Jumping networkë¥¼ ìœ„í•´ ì²« layerë¥¼ feeding í•´ì•¼ í•˜ëŠ”ë°, í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” product i ì— ëŒ€í•œ embedding $h_i^{(0)}$ì„ ì‚¬ìš©í–ˆë‹¤.

$ğ¿$ efficient jumping graph convolution layersë¥¼ ê±°ì¹œ ë’¤ ì–»ê²Œë˜ëŠ” ê° item iì— ëŒ€í•œ **graph-enriched product embedding**ì„ $\tilde{h}_i^{(L)}$ ì´ë¼ í•œë‹¤.

### 3.3.3 **Using Graph-enriched Product Representations for User Preference Modeling**

êµ¬ì„±ëœ SBGê°€ GCNì„ ê±°ì³ ë§Œë“¤ì–´ì§„ ì„ë² ë”©ì„ ZAMì— ë°˜ì˜í•˜ì—¬ Enriched product representationì„ ë°˜ì˜í•œ user embeddingì„ ë§Œë“¤ì–´ ëƒ„.

- **Vanila ZAM**

$$
\boldsymbol{u}=\sum_{i \in I_{u}} \frac{\exp (f(q, i))}{\exp (f(q, \mathbf{0}))+\sum_{i^{\prime} \in I_{u}} \exp \left(f\left(q, i^{\prime}\right)\right)} \boldsymbol{i}
$$

$$
s(q, i)=\left(\boldsymbol{i}^{\top} \tanh \left(\boldsymbol{W}_{f}^{\top} \boldsymbol{q}+\boldsymbol{b}_{f}\right)\right)^{\top} \boldsymbol{W}_{h}
$$

- **Graph-enriched product representations for user preference modeling**

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%204.png>)

$$
\begin{aligned}
&\boldsymbol{u}=\sum_{i \in I_{u} \cup 0} \frac{\exp (s(q, i))}{\exp (s(q, \boldsymbol{0}))+\sum_{i^{\prime} \in I_{u}} \exp \left(s\left(q, i^{\prime}\right)\right)} \tilde{\boldsymbol{h}}_{i}^{(L)} \\
&s(q, i)=\left(\tilde{\boldsymbol{h}}_{i}^{\top} \tanh \left(\boldsymbol{W}_{f}^{\top} \boldsymbol{q}+\boldsymbol{b}_{f}\right)\right)^{\top} \boldsymbol{W}_{h}
\end{aligned}
$$

> _Where $\boldsymbol{W}{h} \in \mathbb{R}^{d{a}}, \boldsymbol{W}{f} \in \mathbb{R}^{d \times d{a} \times d}, \boldsymbol{b}{f} \in \mathbb{R}^{d \times d{a}}$ are the trainable parameters, and $d_{a}$ is the hidden dimension of the user-product attention network. In particular, $\exp (s(q, 0))$ is calculated by Eq. (12) with $i$ as a learnable inquiry vector $0^{\prime} \in \mathbb{R}^{d}$.\_

## 3.4 Model Optimization

ìƒí’ˆ ê²€ìƒ‰ì—ì„œì™€ ì–¸ì–´ëª¨ë¸ ë‘ê°€ì§€ì˜ Loss functionì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©

- Product retrieval loss
  $$
  L_{P R}=-\sum_{(u, i, q)} \log P(i \mid u, q)=-\sum_{(u, i, q)} \log \frac{\exp \left(f\left(\boldsymbol{i}, \boldsymbol{M}_{u q}\right)\right)}{\sum_{i^{\prime} \in C} \exp \left(f\left(\boldsymbol{i}^{\prime}, \boldsymbol{M}_{u q}\right)\right)}
  $$
- Language model loss
  $$
  L_{L M}=-\sum_{i} \log P\left(T_{i} \mid i\right)=-\sum_{i} \sum_{w \in T_{i}} \log \frac{\exp (\tau(w, i))}{\sum_{w^{\prime} \in V} \exp \left(\tau\left(w^{\prime}, i\right)\right)}
  $$
- Total loss

$$
L_{\text {total }}=L_{P R}+L_{L M}=-\sum_{(u, i, q)} \log P(i \mid u, q)-\sum_{i} \log P\left(T_{i} \mid i\right)
$$

> Remark. It is worth noting that we **only use the graph-enriched product embeddings to represent users** but do not use them to represent products themselves in the product retrieval task or the language modeling task, because the **mixed representations may make products lose their uniqueness** and hurt performance, which is verified by our empirical study.

# 4. Experiments

## 4.1 Research Questions

ì´ ë„¤ê°€ì§€ì˜ RQì— ëŒ€í•´ ê²€ì¦í•˜ê³ ì ì‹¤í—˜ ì§„í–‰

1. How is the performances of SBG compared to the base model ZAM?
2. How does SBG perform compared to state-of-the-art methods for personalized product search?
3. How useful is graph convolution? Can the proposed jumping connection alleviate over-smoothing?
4. What is the effect of time interval ğ‘… on the constructed successive behavior graph ğºğ‘†ğµ?

## 4.2 Dataset

[Amazon review dataset](http://jmcauley.ucsd.edu/data/amazon)

ì•„ë§ˆì¡´ì—ì„œ ë°œìƒí•œ ì‚¬ìš©ì-ì•„ì´í…œ ê°„ ê´€ê³„ë¥¼ ê°€ì§„ ë°ì´í„°ì…‹, ìƒí’ˆê²€ìƒ‰/ì¶”ì²œ ì‹œìŠ¤í…œ ì—°êµ¬ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë¨

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%205.png>)

> _Product reviews are generally used as text corpus for representing products or users, and **product categories are used as queries** to simulate a search scenario_

ë…¼ë¬¸ì—ì„œëŠ” 5ê°œ ì´ìƒì˜ í–‰ë™ì„ ê°€ì§€ëŠ” 5-core dataë¥¼ ì‚¬ìš©í–ˆë‹¤.

> If you're using this data for a class project (or similar) please consider using one of these smaller datasets below before requesting the larger files.
>
> **K-cores**Â (i.e., dense subsets): These data have been reduced to extract theÂ [k-core](<https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)>), such that each of the remaining users and items have k reviews each.

## 4.2 Baseline model

**HEM, ZAM / DREM, GraphSRRL**

ì•ì˜ ë‘ ëª¨ë¸ì€ backgroundì—ì„œ ë‹¤ë£¬ latent space ê¸°ë°˜ ëª¨ë¸

ë’¤ì˜ ë‘ ëª¨ë¸ì€ KG,graphë¥¼ í†µí•´ product search ë¥¼ ë‹¤ë¤˜ìœ¼ë©° ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì™”ê¸° ë•Œë¬¸ì— ì„ ì •

## 4.3. **Evaluation**

ê¸°ë³¸ì ìœ¼ë¡œ train/val/test splitì„ ì§„í–‰.

ê° Userì— ë”°ë¼ ì‹œê°„ìˆœìœ¼ë¡œ ë¦¬ë·°ë¥¼ ì •ë ¬í•˜ê³ , ë§ˆì§€ë§‰ì—ì„œ ë‘ë²ˆì§¸ ì‹œí€€ìŠ¤ë¥¼ Validation, ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ë¥¼ Testë¡œì‚¬ìš©.

**Measurement Metric**

**Hit rate(HR@K) :**

ê²€ìƒ‰ê²°ê³¼ê°€ hit í–ˆëŠ”ì§€ì— ëŒ€í•œ ë‹¨ìˆœí•œ rate

![img1.daumcdn.png](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/img1.daumcdn.png>)

**Normalized discounted cumulative gain (NDCG@K)**

ì´ìƒì ì¸ ì»¨í…ì¸  ìˆœì„œì™€ ì‹¤ì œ ìˆœì„œ ê°„ì˜ ì°¨ì´ë¥¼ ì ìˆ˜í™”

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%206.png>)

**Mean reciprocal rank (MRR)**

ì»¨í…ì¸  ìˆœì„œì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%207.png>)

## 4.4 Implementation detail

> For all methods, the batch size is set to 1024, and the ADAM optimizer is used with an initial learning rate of 0.001. All the **entity embeddings are initialized randomly with dimension 64**. #item, user, query

For our SBG, we set the **attention dimension $[ğ‘‘_ğ‘$ to 8]**, and the **user-query balancing** parameter **[ğœ† to 0.5]**.

We employ **4 layers of jumping graph convolution,** and the weight of self-loop is set to 0.1. The strength of **jumping connection [ğ›½] is also set to 0.1.**
The negative sampling rate for each word is set to 5, and that for each item is set to 2.

>

## 4.5 Result

**RQ1&2 : ì„±ëŠ¥í–¥ìƒ**

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%208.png>)

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%209.png>)

- Latent space ê¸°ë°˜ ëª¨ë¸ ì¤‘ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë˜ ZAMì— ë¹„í•´ ëª¨ë“  ì‹¤í—˜ì—ì„œ ìœ ì˜í•œ ì„±ëŠ¥í–¥ìƒ(RQ1)
- SOTA ì˜€ë˜ DREMì— ë¹„í•´ ê±°ì˜ ëª¨ë“  ì‹¤í—˜ì—ì„œ ìœ ì˜í•œ ì„±ëŠ¥í–¥ìƒ(RQ2)
- ZAM ì— ë¹„í•´ DREM ì´ ì‹¤íŒ¨í•˜ë˜ ë¶„ì•¼ì—ì„œë„ ì ì§€ë§Œ ì„±ëŠ¥í–¥ìƒ â†’graph based method ì˜ ì˜í–¥ì´ domainì— ë”°ë¼ ë‹¬ë¼ì§

**RQ3: Graph convolutionì˜ íš¨ìš©**

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%2010.png>)

**RQ4 : ì ì ˆí•œ Rì˜ ì„ íƒ**

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%2011.png>)

Magazineì„ ì œì™¸í•˜ê³  day, weekë¥¼ ë„˜ì–´ê°€ë©´ ì„±ëŠ¥í•˜ë½ì´ ì¼ì–´ë‚¨

ë‹¨, Magazineì€ ë°ì´í„°ì…‹ í¬ê¸°ë„ ì‘ê³ , ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ì„œ Rì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ì¶©ë¶„í•œ ì •ë³´ê°€ ì œê³µë˜ë©° ë°œìƒí•œ ê²°ê³¼ë¡œ ì¶”ì •

# 5. Conclusion

![Untitled](<SBG(for%20gitbook)%204f0e1d73bec545f7937734eec9902841/Untitled%204.png>)

ë³¸ ì—°êµ¬ëŠ” SBGë¥¼ í†µí•´ user embedding ì„ í’ë¶€í™” í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•˜ì˜€ë‹¤. ì´ëŠ” ê¸°ë³¸ì ì¸ ì ì¬ ê³µê°„ ë°©ë²•ë¡ ì˜ ì² í•™ì„ ìœ ì§€í•˜ë©´ì„œ, ì•½ê°„ì˜ ë³€í™”ë¥¼ í†µí•´ ì„±ëŠ¥í–¥ìƒì„ ê°€ì ¸ì™”ê¸° ë•Œë¬¸ì— ì¶”í›„ ë°©ë²•ë¡ ë“¤ì´ ê³ ë„í™” ë˜ì–´ë„ ì‰½ê²Œ ì ìš©ì‹œì¼œì„œ ì„±ëŠ¥í–¥ìƒì„ ë„ëª¨í•  ìˆ˜ ìˆì–´ ë³´ì¸ë‹¤.(plug and play module)

ë‹¨, ë³¸ ì—°êµ¬ëŠ” GCN ê¸°ë°˜ì˜ static graph ë°©ë²•ë¡ ì„ ì±„íƒí•˜ì˜€ê¸° ë•Œë¬¸ì—, ì‹¤ì œ ë¬¸ì œì—ì„œ ì ìš©í•˜ê¸° í˜ë“  ë©´ì´ ìˆì„ ê²ƒì´ë¼ íŒë‹¨ëœë‹¤, ì €ìë“¤ ë˜í•œ dynamic behavior graphë¥¼ ë‹¤ìŒ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œ ì œì‹œí•˜ê³  ìˆë‹¤.

ê´€ë ¨ëœ ì—°êµ¬ë“¤ì„ ì‚´í´ë³´ë©° ì‹¤ì œë¡œ ìƒë‹¹ìˆ˜ ì—°êµ¬ê°€ Amazon, Alibaba ì™€ ê°™ì€ ì»¤ë¨¸ìŠ¤ íšŒì‚¬ë“¤ì˜ í€ë”©ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìŒì„ ê´€ì°°í•  ìˆ˜ ìˆì—ˆë‹¤. ì‹¤ì œ ì‚°ì—…ì—ì„œ ê´€ì‹¬ìˆê²Œ ë°”ë¼ë³´ê³  ìˆëŠ” ì£¼ì œë¼ê³  íŒë‹¨ë˜ì—ˆë‹¤.

ê¶ê¸ˆí–ˆë˜ ì ì€ Queryë¥¼ ì–´ë–»ê²Œ êµ¬í˜„í–ˆëŠ”ì§€ ì¢€ ë” êµ¬ì²´ì ì¸ ì„¤ëª…ì´ ìˆìœ¼ë©´ ì¢‹ì•˜ì„í…ë° ì´ì— ëŒ€í•œ ì •í™•í•œ ì–¸ê¸‰ì´ ì—†ì•˜ë‹¤. Github pageê°€ ê³µê°œë˜ì–´ ìˆì§€ë§Œ, ë‚´ìš©ì´ ì—†ë‹¤.

SBG ëŠ” ê²°êµ­ bipartite graphì— edge êµ¬ì„±ë„ ë‹¨ìˆœí–ˆëŠ”ë°, ë…¼ë¬¸ì˜ intro ì—ì„œ ì£¼ì¥í•˜ë“¯ ì¢€ ë” rich í•œ ì •ë³´ë¥¼ ë‹´ê¸°ìœ„í•´ ë” ë³µì¡í•œ graphë¥¼ êµ¬ì„±í•´ ë³¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ ì‹¶ì€ ìƒê°ì´ ë“¤ì—ˆë‹¤.

# \***\*Author Information\*\***

ê¹€ëŒ€í¬(Kim Daehee) is M.S student in the Graduate school of Knowledge Service Engineering of the Korea Advanced Institute of Science and Technology(KAIST). He has double B.S degrees in System Management Engineering and Computer Science in Sungkyunkwan University(SKKU). His research interest is applying graph neural network to product search and recommendation.He currently works at Knowledge Innovation Research Center, of the KAIST

# 6. Reference

- https://github.com/floatSDSDS/SBG
- [Learning a hierarchical embedding model for personalized product search(SIGIR-2017)](https://scholar.google.com/scholar_url?url=https://dl.acm.org/doi/pdf/10.1145/3077136.3080813&hl=ko&sa=T&oi=gsb-gga&ct=res&cd=0&d=15736059002742053164&ei=pstjYtiTHYySyASZk6HgCA&scisig=AAGBfm17kfq7KLvb8_VrBirjKb8qxDT-7w)
- [A Zero Attention Model for Personalized Product Search](https://arxiv.org/pdf/1908.11322.pdf) (CIKM-2019)
- [Distributed Representations of Sentences and Documents](https://proceedings.mlr.press/v32/le14.pdf) (PMLR-2014)
- [Simple and Deep Graph Convolutional Networks](https://scholar.google.co.kr/scholar_url?url=http://proceedings.mlr.press/v119/chen20v/chen20v.pdf&hl=ko&sa=X&ei=hjEyYvn_AYjwyAS2o4mYAw&scisig=AAGBfm2_hCGohcaQRDILYCo-3dLq2_o3hQ&oi=scholarr) (PMLR-2020)
- [http://jmcauley.ucsd.edu/data/amazon/](http://jmcauley.ucsd.edu/data/amazon/)
- [https://woosikyang.github.io/Graph-Convolutional-Network.html](https://woosikyang.github.io/Graph-Convolutional-Network.html)
- [https://lamttic.github.io/2020/03/20/01.html](https://lamttic.github.io/2020/03/20/01.html)
