---
description : Y Bai et al., / Are Transformers More Robust Than CNNs? / Neurips-2021
---

# **Are Transformers More Robust Than CNNs?** 


## **1. Problem Definition**  

- Vision Transformer(ViT) NetworkëŠ” CNNë³´ë‹¤ ê°•ë ¥í•˜ê³  robustí•˜ë‹¤ê³  ì•Œë ¤ì ¸ìˆë‹¤.
- í•˜ì§€ë§Œ ì´ ì—°êµ¬ì—ì„œëŠ” ëª‡ê°€ì§€ ì‹¤í—˜ì„ í†µí•´ì„œ ê¸°ì¡´ì˜ ì´ëŸ° ë¯¿ìŒì— ì˜ë¬¸ì„ ì œê¸°í•˜ê³  ê³µì •í•˜ê²Œ ì„¤ê³„ëœ ì‹¤í—˜ì¡°ê±´ì—ì„œ ê°•ê±´ì„±ì„ ë‹¤ì‹œ ì¡°ì‚¬í•œë‹¤.
- ê²°ë¡ ì ìœ¼ë¡œ adversarial attackì— CNNë„ ì¶©ë¶„íˆ ê°•ê±´í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆë‹¤
- ê°•ê±´ì„±ì—ëŒ€í•œ ì‹¤í—˜ ë„ì¤‘ì—, ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ pre-trainingì´ transformerê°€ CNNì˜ ì„±ëŠ¥ì„ ë„˜ëŠ”ë° ê¼­ í•„ìš”í•œ ê²ƒì€ ì•„ë‹˜ë„ ë¶€ê°€ì ìœ¼ë¡œ í™•ì¸í–ˆë‹¤.


## **2. Motivation**  

- Pure-attention based modelì¸ transformerê°€ inductive biasì—†ì´ CNNì˜ ì„±ëŠ¥ì„ ë›°ì–´ë„˜ì—ˆê³  Detection, instance segmentation, sementic segmentationì—ì„œë„ ì—°êµ¬ë˜ê³ ìˆë‹¤
- ë˜í•œ ìµœê·¼ ì—°êµ¬ë“¤ì—ì„œ TransformerëŠ” OODì™€ ì ëŒ€ì  ê³µê²©ì— CNNë³´ë‹¤ ê°•ê±´í•¨ì´ ë°í˜€ì¡Œë‹¤
    - *í•˜ì§€ë§Œ*, ì €ìëŠ” ì´ëŸ° ê²°ê³¼ê°€ unfairí•œ í™˜ê²½ì—ì„œ ë„ì¶œë˜ì—ˆë‹¤ê³  ì£¼ì¥í•œë‹¤
    - #paramsê°€ Transformerìª½ì´ ë§ì•˜ê³  training dataset, epochs and augmentation ì „ëµ ë“±ì´ ë™ì¼í•˜ê²Œ ë§ì¶°ì§€ì§€ ì•Šì•˜ë‹¤(ë’¤ì— ì‹¤í—˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´ ViTì—ê²Œ ìœ ë¦¬í•œ ì¡°ê±´ì´ ë‹¤ìˆ˜ ìˆë‹¤)
- ì´ ì—°êµ¬ì—ì„œ ê³µì •í•œ ë¹„êµë¥¼ í†µí•´ ì ëŒ€ì  ê³µê²©ê³¼ OODì— ëŒ€í•œ ê°•ê±´ì„±ì„ í™•ì¸í•  ê²ƒì´ë‹¤
    - CNNì´ Transformerì˜ training recipesë¥¼ ë”°ë¥¸ë‹¤ë©´ perturbationê³¼ patchì— ê¸°ë°˜í•œ attackì— ë” ê°•ê±´í•¨ì„ ë°œê²¬í–ˆë‹¤
    - ì—¬ì „íˆ Transformerê°€ OODì— ê°•ê±´í•¨ì„ ë°œê²¬í–ˆê³  ì´ëŠ” pre-trainingì´ ì—†ì–´ë„ ê°€ëŠ¥í–ˆë‹¤. Ablation studyì—ì„œ self-attentionì´ ì´ëŸ° í˜„ìƒì˜ ì´ìœ ì„ì„ ë°œê²¬í–ˆë‹¤

<aside>

ğŸ’¡  ì´ ì—°êµ¬ê°€ ë‹¤ë¥¸ Architectureë¼ë¦¬ì˜ ê°•ê±´ì„±ì„ ë¹„êµí•˜ëŠ” í‘œì¤€ì´ ë˜ê¸¸ ë°”ë€ë‹¤ê³  ì €ìëŠ” ë°íˆê³  ìˆìŠµë‹ˆë‹¤

</aside>



## **3. Method**  
- ì´ ì±•í„°ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¬ë‹¤. ëª¨ë‘ ì‹¤í—˜ì—ì„œ ìì£¼ ë“±ì¥í•  ë‚´ìš©ì´ë¯€ë¡œ ì£¼ì˜ê¹Šê²Œ ìˆ™ì§€í•˜ê¸¸ ë°”ëë‹ˆë‹¤.
1. CNNê³¼ ViTì˜ í•™ìŠµì¡°ê±´ ë¹„êµ
2. ë‹¤ì–‘í•œ Attackê³¼ OOD Dataset

## 3.1 Training CNNs and Transformer

- í•™ìŠµ í›„ CNNì™€ ViTì˜ Top-1 AccëŠ” 76.8, 76.9ë¡œ ë§¤ìš° ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ëƒ„

### CNN

- ResNet-50ì´ ViTì™€ ë¹„ìŠ·í•œ #paramsë¥¼ ê°€ì§€ë¯€ë¡œ ì±„íƒ
- ImageNetì— í•™ìŠµ
- ê¸°íƒ€ í•™ìŠµ ë””í…Œì¼(SGD-momentum, 100eph, L2ê·œì œ)

### ViT

- ì™¸ë¶€ ë°ì´í„°ì—†ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ DeiTì˜ recipeë¥¼ ë”°ë¼ì„œ DeiT-S(#paramsê°€ ResNet50ê³¼ ë¹„ìŠ·)ë¥¼ default ViTë¡œ ì±„íƒí•¨
- AdamW, 3ê°œì˜ Aug(Rand, Cut, MixUp)
- ResNetê³¼ í•™ìŠµ í™˜ê²½ì„ ë§ì¶”ê¸°ìœ„í•´ Erasing, Stochastic Depth, Repeated Augë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ. DeiTëŠ” 300ephí•™ìŠµë˜ì§€ë§Œ ê°™ì€ ì´ìœ ë¡œ 100ephë§Œ í•™ìŠµ

## 3.2 Robustness Evaluations

### 3.2.1 Adversarial Attack
#### PGD
- PGD(Projected Gradient Descent) : ì‚¬ëŒì€ í™•ì¸í•˜ê¸° ì–´ë µì§€ë§Œ ê¸°ê³„ë¥¼ ì†ì¼ ìˆ˜ ìˆëŠ” ì„­ë™

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F42d2c8ef-1b52-4718-a081-9f6d2426de53%2FUntitled.png?table=block&id=c8d0616a-d5f1-492b-8c77-a31b94d5b362&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

#### TPA
- TPA : textureê°€ ìˆëŠ” patchë¥¼ ë¶™ì—¬ ë„¤íŠ¸ì›Œí¬ë¥¼ ì†ì´ëŠ” attack


![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc37dcc0d-a43c-4f71-a9c6-cf7f25bf73e8%2FUntitled.png?table=block&id=0da98098-a42c-45d4-98ee-f9187cb9e2cd&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=1030&userId=&cache=v2)
        
![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6764d1d3-4b81-4d2b-9bb1-87e945c2d3c4%2FUntitled.png?table=block&id=2687d828-3a4f-4982-804a-c8119aa82f0f&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=1610&userId=&cache=v2)
        
### 3.2.2 OOD 
- ë…¼ë¬¸ê³¼ PaperWithCode(PWC)ì— ìˆëŠ” ì„¤ëª…ì´ ì¡°ê¸ˆ ë‹¤ë¥¸ë° PWCë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ì—ˆë‹¤
    
    - *mageNet-A* : ResNet modelì´ ê°•í•œ í™•ì‹ ìœ¼ë¡œ í‹€ë¦° ì´ë¯¸ì§€ì…‹. ê¸°ê³„í•™ìŠµ ëª¨ë¸ì´ ì–´ë ¤ì›Œí•˜ëŠ” ì¦‰ í•™ìŠµ ë¶„í¬ë‘ì€ ì¢€ ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤ì˜ ëª¨ì„ì´ë‹¤. ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë³´ë©´ ì™œ ê·¸ëŸ° í‹€ë¦° ë‹µì„ ëƒˆëŠ”ì§€ ì•Œ ê²ƒë„ ê°™ë‹¤
      ![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc7c1a4b6-25a3-4a24-bb46-5ffb43f1f7f2%2FUntitled.png?table=block&id=4b49d8f7-468b-4c9c-a6c4-5b7c5056c74e&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)
        
    - *ImageNet-C* : ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ Augmentationì´ ì ìš©ëœ ì´ë¯¸ì§€ì…‹
        
      ![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3802b66c-15d1-47f4-8702-7160fbb557c2%2FUntitled.png?table=block&id=c9fb7059-3a0e-4dd5-a9d2-6b413ed3c73b&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)
        
    - *Stylized ImageNet* :  ì´ë¯¸ì§€ë‹¹ ë‹¤ì–‘í•œ textureë¥¼ ì…í•œ ë°ì´í„°ì…‹
        
      ![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6ebce612-8a69-4031-8c37-1a34b32c60b9%2FUntitled.png?table=block&id=ce5c92ce-3ea5-4672-b32a-1f55c8b11ec9&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)
        






## **4. Experiment**  
- ì‹¤í—˜ì€ í¬ê²Œ ë‘ ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ìˆìŠµë‹ˆë‹¤.
1. ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ê°•ê±´ì„±
2. OOD Sampleì— ëŒ€í•œ ê°•ê±´ì„±

### **4.1 Adversarial Robustness**  



- 5000ì¥ì˜ ImageNet ê²€ì¦ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì˜€ìŒ
    
### 4.1.1 Robustness to Perturnation-Based Attacks

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fba30da01-1ae5-4c23-8e2f-b7978ba7c328%2FUntitled.png?table=block&id=6b36f65d-49dc-43db-80c8-9066b77e8310&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=1720&userId=&cache=v2)

- AutoAttackì˜ ì„­ë™ì„ ë†’ì´ë‹ˆ ì™„ì „íˆ fooled
- ê·¸ëŸ¬ë‚˜ ë‘ ëª¨ë¸ì´ ì „í˜€ Adversarial trainingë˜ì§€ ì•Šì•˜ìŒì„ ê¸°ì–µí•˜ì

    #### Adversarial Training

    ![img](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fe2ae3fd7-3323-4575-85c3-7cf2bbe68ca8%2FUntitled.png?table=block&id=1a72ebdb-7f9b-42eb-a7ba-1e86e133f246&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=640&userId=&cache=v2)

    

    | ![](https://latex.codecogs.com/gif.latex?\theta) | parameters | ![](https://latex.codecogs.com/gif.latex?\mathbb{S}) | max ![](https://latex.codecogs.com/gif.latex?\epsilon) |
    | --- | --- | --- | --- |
    | ![](https://latex.codecogs.com/gif.latex?\mathbb{E}) | expectation | ![](https://latex.codecogs.com/gif.latex?\epsilon) | perturbation |
    | ![](https://latex.codecogs.com/gif.latex?x,y) | data | ![](https://latex.codecogs.com/gif.latex?\mathbb{D}) | dataset |
    
    - ì„­ë™ì„ ì£¼ì–´ì„œ Lossë¥¼ ìµœëŒ€í™”í•˜ëŠ” sample ![](https://latex.codecogs.com/gif.latex?x+\epsilon)ì—ì„œì˜ ìµœì  parameterë¥¼ ì°¾ìœ¼ë¼ëŠ” ë‚´ìš©ì˜ ìˆ˜ì‹ì´ë‹¤
    - ì •í™•íˆëŠ” PGDê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ë° ë°˜ë³µì ì¸ stepì„ í†µí•´ì„œ ìµœì  ê³µê²©ì§€ì ì„ ì°¾ëŠ” ë°©ë²•ì´ë¼ ì´í•´í•˜ë©´ ë˜ê² ë‹¤

    #### Adversarial Training on Transformers

    - CNNì€ ë¬¸ì œ ì—†ì—ˆìœ¼ë‚˜ TransformerëŠ” ê°•í•œ Augmentationì´ PGDì™€ í•¨ê»˜ ì ìš©ë˜ë‹ˆ collapseë˜ì–´ë²„ë¦¬ëŠ” ë¬¸ì œê°€ ìˆì—ˆë‹¤
    - ë”°ë¼ì„œ Augmentationì„ ephì¦ê°€ì— ë”°ë¼ ì ì  ê°•ë„ë¥¼ ë†’ì—¬ê°€ë©° í•™ìŠµí•œ ê²°ê³¼ 44%ì˜ robustnessë¥¼ ì–»ì—ˆë‹¤

    #### Transformers with CNNsâ€™ Training Recipes

    - CNNì—ì„œ ì‚¬ìš©ëœ í•™ìŠµì¡°ê±´(M-SGD, ê°•í•œ Augmentation ë°°ì œ)ì„ Transformerì— ì‚¬ìš©í–ˆë”ë‹ˆ í•™ìŠµì´ ì•ˆì •ë˜ê¸´ í–ˆì§€ë§Œ clean dataì— ëŒ€í•œ ì„±ëŠ¥ê³¼ PGD-100ì— ëŒ€í•œ ë°©ì–´ìœ¨ì´ í•˜ë½í–ˆë‹¤
    - ì´ëŸ¬í•œ í˜„ìƒì´ ë‚˜íƒ€ë‚œ ì´ìœ ëŠ” ê°•í•œ Augmentationì„ ê·œì œí•´ overfittingì´ ì‰½ê²Œ ì¼ì–´ë‚¬ê¸° ë•Œë¬¸ì´ê³  ì´ì „ ì—°êµ¬ì—ì„œ ë°í˜€ì¡Œë“¯ì´ Transformer ìì²´ê°€ SGDì™€ê°™ì€ optimizerì—ì„œ ìµœì ì ì„ ì˜ ì°¾ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì´ë‹¤

    #### CNNs with Transformersâ€™ Training Recipes

    ![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2582dadc-09e2-4efd-a35f-122ab9f221a0%2FUntitled.png?table=block&id=8ff952c2-ab75-4383-900e-8222603c5c14&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

    - ResNet-50 + ReLUì˜ ê²°ê³¼ë¥¼ ë³´ë©´ ViTë³´ë‹¤ ëœ ê°•ê±´í•˜ë‹¤. ì´ëŸ° ì‹¤í—˜ê²°ê³¼ì— ëë‚˜ì§€ ì•Šê³  ì €ìë“¤ì€ ìƒˆë¡œìš´ ì‹¤í—˜ì„ í•´ë³¼ motivationì„ ì–»ì—ˆë‹¤ê³ í•œë‹¤. Transformerì˜ recipesë¥¼ CNNì— ì ìš©í•´ ë¹„êµí•´ë³´ëŠ” ê²ƒì´ë‹¤
    - Transformerê°€ ì“°ëŠ” optimizerì™€ strong regularizationëŠ” ë³„ íš¨ê³¼ê°€ ì—†ê±°ë‚˜ í•™ìŠµì—ì„œ collapseë¥¼ ì¼ìœ¼ì¼°ë‹¤
    - non-smoothí•œ íŠ¹ì„±ì„ ê°€ì§„ ReLUë¥¼ transoformerê°€ ì“°ëŠ” GELUë¡œ ëŒ€ì²´í–ˆë‹¤. ReLUëŠ” ì ëŒ€ì  ê³µê²©ì— ì·¨ì•½í•œ activationì„ì´ ì•Œë ¤ì ¸ìˆë‹¤
    - **ê·¸ ê²°ê³¼ ResNet-50 + GELUëŠ” DeiTì— í•„ì í•˜ëŠ” ì ëŒ€ì  ê³µê²©ì—ëŒ€í•œ ì„±ëŠ¥ì„ ë‚´ì—ˆìœ¼ë©° ì´ëŠ” ê¸°ì¡´ ì—°êµ¬ì˜ ê²°ë¡ ì„ ë°˜ë°•í•˜ëŠ” ê²ƒì´ë‹¤**


### 4.1.2 Robustness to Patch-Based Attacks

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2dfb3c60-828a-471a-b938-f698c9661cc8%2FUntitled.png?table=block&id=b2385299-43ed-440d-94ee-e2a9ef8e8a02&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- defaultë¡œ 4ê°œì˜ patchë¡œ ëŒ€ìƒ ì´ë¯¸ì§€ì˜ ì „ì²´ ë©´ì ì— 10%ì•ˆìª½ì´ ë˜ê²Œ attackí–ˆë‹¤. ë‘ ëª¨ë¸ ëª¨ë‘ TPAì— ëŒ€í•œ ì ëŒ€ì  í•™ìŠµì€ í•˜ì§€ ì•Šì•˜ë‹¤. ê·¸ ì´ìœ ê°€ ì¢€ í—·ê°ˆë¦¬ëŠ”ë° ì ëŒ€ì  í•™ìŠµì‹œì— non-trivial ê·¸ëŸ¬ë‹ˆê¹Œ, ì„±ëŠ¥ì´ ë„ˆë¬´ ì¢‹ì•„ì ¸ì„œ ë¹„êµê°€ ì–´ë µë‹¤ëŠ” ì·¨ì§€ë¡œ í•´ì„í–ˆë‹¤
- Table 3ì˜ ê²°ê³¼ë¥¼ ë³´ë©´ CNNì€ Transformerì˜ ê°•ê±´ì„±ì— ë¯¸ì¹˜ì§€ ëª»í•˜ê³  ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ ì£¼ì¥ì´ ë§ì•„ë³´ì¸ë‹¤
- í•˜ì§€ë§Œ ì €ìë“¤ì€ TPAì˜ íŠ¹ì„±ì— ì£¼ëª©í•˜ì—¬ ìƒˆë¡œìš´ ì§€ì ì„ í•œë‹¤. TPAëŠ” ì´ë¯¸ì§€ìœ„ì— ì¸ìœ„ì ì¸ patchê°€ ë¶™ëŠ” í˜•íƒœì´ë‹¤. ì´ëŠ” patchë¥¼ ì˜ë¼ ë¶™ì´ê±°ë‚˜ ì‚­ì œí•˜ëŠ” CutMixì™€ ìœ ì‚¬í•˜ë©° CutMixëŠ” ViTì—ë§Œ ì ìš©ë˜ì—ˆê¸°ë•Œë¬¸ì— ViTì—ê²Œ TPAê°€ ë‹¹ì—°íˆ ìœ ë¦¬í•œ taskë¼ëŠ” ê²ƒì´ë‹¤

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffa8c3d16-f52a-4edc-af2b-262d2b981013%2FUntitled.png?table=block&id=12f54bf2-8f4f-4a25-8ce2-9f1546fe3dec&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- ê·¸ì—ëŒ€í•œ ì¦ëª…ìœ¼ë¡œ ViTì— ì ìš©ë˜ì—ˆë˜ 3ê°œì˜ strong augmentationì„ ì ìš©í•´ ResNet-50ì„ í•™ìŠµì‹œì¼œ TPAì—ëŒ€í•œ ì„±ëŠ¥ì„ ì‚´íˆë”ë‹ˆ table 4ì™€ ê°™ì•˜ë‹¤
- ê°€ì„¤ëŒ€ë¡œ CutMixì˜ ìœ ë¬´ê°€ ì„±ëŠ¥ì„ í¬ê²Œ ì¢Œìš°í–ˆë‹¤
- **RandAug+CutMixì—ì„œ DeiTì˜ TPAì—ëŒ€í•œ ê°•ê±´ì„±ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ê³  ì´ëŠ” ê¸°ì¡´ ì—°êµ¬ë“¤ì´ ì£¼ì¥í•œ patch-based ê³µê²©ì—ëŒ€í•œ transformerì˜ ê°•ê±´ì„±ì´ CNNë³´ë‹¤ ì¢‹ë‹¤ëŠ” ì£¼ì¥ì„ ë°˜ë°•í•œë‹¤**






### **4.2 Robustness on OOD Samples**  
- ì´ ì±•í„°ì—ì„œëŠ” DeiTì˜ Recipes ì¤‘ ì–´ë–¤ ê²ƒì„ ì–´ë–»ê²Œ ResNetì— ì ìš©í•  ê²ƒì¸ì§€ ì •í•œ ë’¤ì— ResNetì„ í•™ìŠµ í›„ ì„±ëŠ¥ì„ DeiTì™€ ë¹„êµí•˜ëŠ” ë‚´ìš©ì„ ë‹´ê³ ìˆë‹¤
  

### 4.2.1 Aligning Training Recipes
    
![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F75d0a14e-e22e-414d-bfc2-ea400cfc30e3%2FUntitled.png?table=block&id=b19f60d9-0388-46c5-ae5a-a6a336ced8ba&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— pre-trainingì—†ì´ë„ ViTê°€ ë” robustí–ˆë‹¤(ResNet-50* ì€ í›„ìˆ )

#### A Fully Aligned Version(Step 0)

- ResNet-50* ì€ DeiTì˜ recipeë¥¼ ë”°ë¼ opimizer(Adam-W), lr scheduler and strong augmentationì„ ì ìš©í–ˆì§€ë§Œ ResNet-50ì— ë¹„í•´ì„œ ëˆˆì— ë„ëŠ” ì„±ëŠ¥ í–¥ìƒì€ ì—†ì—ˆë‹¤(Table 5)
    - ë”°ë¼ì„œ ì„¸ ìŠ¤í…ì„ ê±°ì³ DeiTì™€ ì¡°ê±´ì„ ê°™ì´í•˜ëŠ” ìµœì ì˜ setupì„ ì°¾ì•„ë³¸ë‹¤(Ablation)

#### Step 1 : Aligning Learning Rate Scheduler

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0c01f9e2-f46e-45f4-84b8-942bed068ebb%2FUntitled.png?table=block&id=1ad859f3-1fe2-49d1-8b76-d8e45d7bc05e&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- Table 6ì—ì„œ, step decayë³´ë‹¤ cosine schedule decayë¥¼ ì“°ëŠ” ê²ƒì´ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìœ¼ë¯€ë¡œ ì‚¬ìš©

#### Step 2 : Aligning Optimizer

- Table 6ì—ì„œ, Adam-Wë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ResNetì˜ ì„±ëŠ¥ê³¼ ê°•ê±´ì„±ì„ ëª¨ë‘ í•´ì³¤ë‹¤. ë”°ë¼ì„œ M-SGDì‚¬ìš©

#### Step 3 : Aligning Augmentation Strategies

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd72d53b4-165c-457e-b200-8a5e0cb2a3d4%2FUntitled.png?table=block&id=b83065cc-0032-4def-9fda-9222d4f6405a&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- ë‹¤ì–‘í•œ ì¡°í•©ì„ ì¡°ì‚¬í–ˆëŠ”ë° ì¼ë‹¨ strong augì˜ ì¡´ì¬ê°€ OODì—ì„œì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚´. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì œì¼ ì¢‹ì€ ì„±ëŠ¥ì€ ì—¬ì „íˆ DeiTì˜€ë‹¤

#### Comparing ResNet With Best Training Recipes To DeiT-S

- Stepì„ ê±°ì³ ì„¸ê°€ì§€ training recipeë¥¼ ì¡°ì‚¬í–ˆìŒì—ë„ ResNetì€ DeiTì˜ OODì„±ëŠ¥ì„ ë”°ë¼ê°€ì§€ ëª»í–ˆë‹¤
    - **ì´ê²ƒì€ Transformerì™€ CNNì‚¬ì´ OODì„±ëŠ¥ì„ ê°€ë¥¸ keyê°€ training recipeì— ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŒì„ ì•”ì‹œí•œë‹¤**

#### Model Size

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd3c90f31-4df2-49d1-ac82-28d17a8d0a13%2FUntitled.png?table=block&id=aaa41c37-ccb1-42a3-b935-2d68a9ad9890&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- #paramsì— ë”°ë¥¸ ë¹„êµë„ í•˜ê¸°ìœ„í•´ ìƒˆë¡œìš´ ì‹¤í—˜ì„ í•˜ì˜€ë‹¤. ResNetì— * ì´ ë¶™ì€ ê²ƒì€ ì„¸ ê°€ì§€ recipeì„ ëª¨ë‘ ì ìš©í•œ ê²ƒì´ê³  BestëŠ” ìœ„ì—ì„œ ì°¾ì€ ì¡°í•©ì´ë‹¤
- ì „ì²´ì ìœ¼ë¡œ DeiTê°€ parameter ìˆ˜ì˜ ë³€í™”ì—ë„ ì œì¼ ì¢‹ì€ OODì„±ëŠ¥ì„ ë³´ì˜€ë‹¤

### 4.2.2 Distillation

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffa5bb1f6-fea4-4c8b-9687-c7c1fa11baca%2FUntitled.png?table=block&id=adfdb9ee-7ef8-4478-a770-81a1ffd5cffd&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- ê²°ê³¼1(T:DeiT, S:ResNet) : ì•Œë ¤ì§„ ìƒì‹ê³¼ ë‹¤ë¥´ê²Œ Studentê°€ ë” ë‚˜ìœ ì„±ëŠ¥. DeiTê°€ ë” ì¢‹ì€ ì„±ëŠ¥
- ê²°ê³¼2(T:ResNet, S:DeiT) : DeiTê°€ ë” ì¢‹ì€ ì„±ëŠ¥
- **4.2.1ê³¼ 4.2.2ì˜ ê²°ê³¼ë¡œ ë¯¸ë£¨ì–´ë³¼ ë•Œ, DeiTì˜ ê°•ë ¥í•œ ì¼ë°˜í™” ì„±ëŠ¥ì€ training setupê³¼ knowledge distillationì´ ì•„ë‹Œ Transformerì˜ êµ¬ì¡° ìì²´ì—ì„œ ì˜¨ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤**

### 4.2.3 Hybrid Architecture

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F83acabba-926e-401e-90ad-3a32015f25b8%2FUntitled.png?table=block&id=d861a6b9-a59d-4374-9d96-d28df94dc734&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- Hybrid-DeiTëŠ” ResNet-18ì˜ res_4 blockì˜ outputì„ DeiT-Miniì—ê²Œ ë„˜ê²¨ì£¼ëŠ” hybridëª¨ë¸ì´ë‹¤
- CNN(ResNet)ì— transformerêµ¬ì¡°ê°€ ë”í•´ì§€ë‹ˆ ResNet-50ë³´ë‹¤ ë” ê°•ê±´í•´ì¡Œë‹¤. í•˜ì§€ë§Œ pureí•œ transformerìì²´ë³´ë‹¤ëŠ” ëª»í–ˆë‹¤. **ì´ê²ƒì€ Transformerì˜ self-attention mechanismì´ ê°•ê±´ì„± í–¥ìƒì— í•„ìˆ˜ì ì¸ ìš”ì†Œì„ì„ ì¦ëª…í•œë‹¤**

### 4.2.4 300-Epoch Training

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc617bd9b-729d-491b-97bf-16b2a7dbf5e4%2FUntitled.png?table=block&id=83662768-3347-454d-9f98-71b5982a5d09&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

![Untitled](https://erratic-tailor-f01.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd6da19c3-5e41-4f0f-bcc1-a34b56f57afc%2FUntitled.png?table=block&id=5832f034-16d7-4865-aaf8-bc9336a67789&spaceId=ad2a71b5-1b0d-4734-bbc4-60a807442e5d&width=2000&userId=&cache=v2)

- CNNêµ¬ì¡°ëŠ” 100ephí•™ìŠµë˜ëŠ”ê²Œ ì¼ë°˜ì ì´ì§€ë§Œ TransformerëŠ” 300eph ì •ë„ë¡œ ë§ì´ í•™ìŠµëœë‹¤. ì´ëŸ° í˜•í‰ì„±ì— ë§ì¶”ì–´ í•™ìŠµí–ˆë”ë‹ˆ Table 9ì™€ ê°™ì•˜ë‹¤
- ë” ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ì„œ ResNetì˜ clean accê°€ DeiTë³´ë‹¤ ë†’ì€ 101,200ì„ ê°€ì ¸ì™€ ì‹¤í—˜í–ˆë‹¤. ì—­ì‹œ DeiTê°€ ë” ë†’ì€ OODì„±ëŠ¥ì„ ë³´ì˜€ë‹¤
- **ì´ê²ƒìœ¼ë¡œ Transformerê°€ CNNë³´ë‹¤ OODì— ë” ê°•ê±´í•˜ë‹¤ê³  ë§í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤**







## **5. Conclusion**  

- unfairí•œ ì¡°ê±´ì—ì„œ ì‹¤í–‰ë˜ë˜ ì‹¤í—˜ì„ ì ì ˆí•œ ì¡°ì¹˜ë¥¼ í†µí•´ ë¹„êµí•˜ë‹ˆ TransformerëŠ” ì ëŒ€ì  ê³µê²©ì—ì„œ CNNë³´ë‹¤ ê°•ê±´í•˜ì§€ ì•Šì•˜ë‹¤
- ë˜í•œ OODì—ì„œì˜ Transformerì„±ëŠ¥ì€ self-attentionê³¼ ê´€ë ¨ì´ ìˆìŒì„ í™•ì¸í–ˆë‹¤
- ì´ ì—°êµ¬ë¡œ transformerì— ëŒ€í•œ ì´í•´ê°€ í–¥ìƒë˜ê³  transformerê³¼ CNNì‚¬ì´ ê³µì •í•œ ë¹„êµê°€ ê°€ëŠ¥í•´ì§€ê¸¸ ë°”ë€ë‹¤

### ê°œì¸ì  ì˜ê²¬ìœ¼ë¡œ..
- ViTì˜ ë“±ì¥ì€ ë§ì€ ì´ìŠˆë¥¼ ë‚³ì•˜ìŠµë‹ˆë‹¤. ì²˜ìŒ CNNì´í›„ Imageë¶„ë¥˜ë¥¼ ìœ„í•œ ê·¼ì›ì ì¸ ìƒˆë¡œìš´ ë°©ë²•ë¡  ì œì‹œì˜€ê³  ë¬´ì—‡ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ìŠµë‹ˆë‹¤. ì‹¬ì§€ì–´ ìµœê·¼ ì—°êµ¬ë“¤ì—ì„œëŠ” ViTê°€ CNNë³´ë‹¤ ê°•ê±´í•˜ê¸°ê¹Œì§€ í•˜ë‹¤ëŠ” ê²°ê³¼ë¥¼ ë„ì¶œí•˜ë©´ì„œ Visionì˜ ì˜ì—­ì€ ì´ì œ (ì—„ì²­ë‚œ pretrain datasetì„ ê°€ì§„ ì‚¬ì—…ì²´ê°€ í•™ìŠµí•œ) ViTê°€ ëª¨ë‘ ê°€ì ¸ê°ˆ ê²ƒì´ë¼ëŠ” ì˜ˆìƒì„ í•˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ í•™ê³„ì˜ ì´ëŸ° ë¯¿ìŒ ìì²´ì— ì˜ë¬¸ì„ ê°€ì§€ê³  ë„ì „í•˜ëŠ”ê²Œ ì‰¬ìš´ì¼ì´ ì•„ë‹ˆì—ˆì„ ê²ƒì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤. ì´ëŸ° ì—°êµ¬ë¥¼ ë‚´ë†“ì€ ì—°êµ¬ìë“¤ì˜ ì‹¤ë ¥ê³¼ ìì‹ ê°ì—ì„œ ë˜ í•œë²ˆ ê²¸ì†í•´ì•¼í•¨ì„ ëŠë‚ë‹ˆë‹¤.


---  
## **Author Information**  

* í™ì„±ë˜ SungRae Hong
    * Master's Course, KAIST Knowledge Service Engineering 
    * Interested In : SSL, Vision DL, Audio DL
    * Contact : sun.hong@kaist.ac.kr

## **6. Reference & Additional materials**  

Please write the reference. If paper provides the public code or other materials, refer them.  

* Github Implementation  
* Reference  

